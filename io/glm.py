import itertools

import numpy as np
import xarray as xr

def fix_event_locations(event_lats, event_lons, is_xarray=False):
    """ event_lats and event_lons are netCDF4 Variables, or
        if is_xarray=True, xarray Variables.
    
        returns fixed (event_lats, event_lons)
    
        This function is used to correct for the NetCDF-Java convention of writing 
        signed int16 and tagging it with an _Unsigned attribute. Per 
        http://www.unidata.ucar.edu/software/thredds/current/netcdf-java/CDM/Netcdf4.html
        NetCDF Java cannot write a proper unsigned integer.
    
        If the version of netcdf4-python used to read the data is >=1.2.8, then 
        this function is not needed. The issue corrected by this function was 
        built into netcdf4-python in PR #658 developed in response to issue #656. 
    
        xarray turns off auto-scaling, which also turns off the unsigned int
        correction in netCDF4-python. xarray then applies the scale/offset itself.
        Therefore, this function is still needed to undo xarray's scale/offset, 
        followed by unsigned int conversion and reapplication of the scale/offset.
        
        and so the scaling must be worked around 

    """
    
    # From PUG spec, and matches values in file.
    lon_fov = (-156.06, -22.94)
    dlon_fov = lon_fov[1]-lon_fov[0]
    lat_fov = (-66.56, 66.56)
    scale_factor = 0.00203128

    
    if is_xarray==True:
        # unscale the data 
        unscale_lat = ((event_lats - lat_fov[0])/scale_factor).data.astype('int32')
        unscale_lon = ((event_lons - lon_fov[0])/scale_factor).data.astype('int32')
        event_lats = unscale_lat
        event_lons = unscale_lon
    else: # is NetCDF Variable
        event_lons.set_auto_scale(False)
        event_lats.set_auto_scale(False)
        event_lons = event_lons[:].astype('int32')
        event_lats = event_lats[:].astype('int32')

    unsigned = 2**16
    event_lons[event_lons < 0] += unsigned
    event_lats[event_lats < 0] += unsigned
    
    event_lons_fixed = (event_lons)*scale_factor+lon_fov[0]
    event_lats_fixed = (event_lats)*scale_factor+lat_fov[0]
    
    return event_lats_fixed, event_lons_fixed



class GLMDataset(object):
    def __init__(self, filename):
        """ filename is any data source which works with xarray.open_dataset """
        self.dataset = xr.open_dataset(filename)

        self.fov_dim = 'number_of_field_of_view_bounds'
        self.wave_dim = 'number_of_wavelength_bounds'
        self.time_dim = 'number_of_time_bounds'
        self.gr_dim = 'number_of_groups'
        self.ev_dim = 'number_of_events'
        self.fl_dim = 'number_of_flashes'

        self.split_flashes = self.dataset.groupby('flash_id')
        self.split_groups = self.dataset.groupby('group_parent_flash_id')
        self.split_events = self.dataset.groupby('event_parent_group_id')
        
        if len(getattr(self.dataset, self.fl_dim)) > 0:
            self.energy_min, self.energy_max = 0, self.dataset.flash_energy.max()
        else:
            # there are no flashes
            pass
            



        # for k, v in self.split_groups.groups.items():
        #     print k,v

    @property
    def fov_bounds(self):
#         lat_bnd = self.dataset.lat_field_of_view_bounds.data
#         lon_bnd = self.dataset.lon_field_of_view_bounds.data
        lat_bnd = self.dataset.event_lat.min().data, self.dataset.event_lat.max().data
        lon_bnd = self.dataset.event_lon.min().data, self.dataset.event_lon.max().data
        return lon_bnd,lat_bnd

    def get_flash(self, some_flash):
        """ Subset the dataset to a single flash whose index is given by some_flash"""
        
        # The list of indices returned by the group dictionary correspond to the 
        # indices automatically generated by xarray for each dimension, and
        # don't correspond to the flash_id and group_id columns
        fl_idx = self.split_flashes.groups[some_flash]
        gr_idx = self.split_groups.groups[some_flash]

        #get just this flash and its groups
        grp_sub = self.dataset[{self.fl_dim:fl_idx,
                                self.gr_dim:gr_idx
                               }]

        # get event ids for each group and chain them together into one list
        ev_iter = (self.split_events.groups[gid] for gid in grp_sub.group_id.data)
        ev_idx = list(itertools.chain.from_iterable(ev_iter))

        # get just the events that correspond to this flash
        this_flash = grp_sub[{self.ev_dim:ev_idx}]
        return this_flash

